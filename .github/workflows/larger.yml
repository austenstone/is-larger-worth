name: "2. Larger Runners Benchmark"

on:
  workflow_dispatch:

jobs:
  benchmark:
    strategy:
      fail-fast: false
      matrix:
        runs-on: ['ubuntu-latest', '4-core', '8-core', '16-core', '32-core', '64-core']
    uses: ./.github/workflows/benchmark.yml
    with:
      runs-on: ${{ matrix.runs-on }}
  summary:
    runs-on: ubuntu-latest
    needs: benchmark
    steps:
      - run: echo ${{ toJSON(needs.benchmark) }}
      - uses: actions/github-script@v6
        id: my-script
        with:
          result-encoding: string
          script: |
            await core.summary
            .addHeading('Test Results')
            .addTable([
              [{data: 'File', header: true}, {data: 'Result', header: true}],
              ['foo.js', 'Pass ✅'],
              ['bar.js', 'Fail ❌'],
              ['test.js', 'Pass ✅']
            ])
            .addLink('View staging deployment!', 'https://github.com')
            .write()